# The Evolution of AI Regulation: Global Frameworks Take Shape

*Based on information available up to October 2024*

As AI systems continue to advance in capabilities and adoption, regulatory frameworks around the world have been evolving to address potential risks while enabling innovation. The EU's AI Act established a tiered risk-based approach that has influenced similar frameworks in other regions, while the US has implemented its AI Executive Order focusing on safety, security, and alignment with American values.

## Key Developments

- Implementation phases of the EU AI Act have begun rolling out, with companies adapting to compliance requirements
- US federal agencies continue working on AI risk assessment frameworks outlined in the Executive Order
- International standardization bodies advance work on technical standards for AI safety and evaluation
- China's approach to AI regulation continues to focus on algorithm transparency and data security
- Global coordination efforts through the G7 AI Hiroshima Process and other multilateral forums

## Industry Response

Major AI developers have strengthened their internal governance protocols, with many adopting voluntary commitments around AI safety testing, security measures, and transparency reporting. Several leading companies have established external review boards and expanded red-teaming exercises before model releases.

## Looking Forward

As foundation models become more powerful and ubiquitous, tensions between rapid innovation and appropriate safety measures continue to drive policy conversations. Observers note that finding the right balance between enabling technological advancement and preventing potential harms remains challenging for policymakers worldwide.
